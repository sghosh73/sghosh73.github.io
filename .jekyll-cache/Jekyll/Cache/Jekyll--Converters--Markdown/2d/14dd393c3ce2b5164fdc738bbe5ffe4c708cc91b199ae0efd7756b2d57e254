I"ÈO<!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2025</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div>

        <!-- Entry bib key -->
        <div id="ghosh2025samplealignsynthesizegraphbased" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs</div>
          <!-- Author -->
          <div class="author">
          
                  <em>Sayan Ghosh</em>,&nbsp;Shahzaib Saqib Warraich,&nbsp;Dhruv Tarsadiya,&nbsp;Gregory Yauney,&nbsp; and 
                Swabha Swayamdipta

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>arXiv preprint arXiv:2510.03527</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2510.03527.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Language models can be sampled multiple times to access the distribution underlying their responses, but existing methods cannot efficiently synthesize rich epistemic signals across different long-form responses. We introduce Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents shared information, as well as semantic variation in a set of sampled LM responses to the same prompt. We construct ConGrs using a light-weight lexical sequence alignment algorithm from bioinformatics, supplemented by the targeted usage of a secondary LM judge. Further, we design task-dependent decoding methods to synthesize a single, final response from our ConGr data structure. Our experiments show that synthesizing responses from ConGrs improves factual precision on two biography generation tasks by up to 31% over an average response and reduces reliance on LM judges by more than 80% compared to other methods. We also use ConGrs for three refusal-based tasks requiring abstention on unanswerable queries and find that abstention rate is increased by up to 56%. We apply our approach to the MATH and AIME reasoning tasks and find an improvement over self-verification and majority vote baselines by up to 6 points of accuracy. We show that ConGrs provide a flexible method for capturing variation in LM responses and using the epistemic signals provided by response variation to synthesize more effective responses.</p>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CoRL</abbr></div>

        <!-- Entry bib key -->
        <div id="anwar2025efficient" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection</div>
          <!-- Author -->
          <div class="author">
          Abrar Anwar,&nbsp;Rohan Gupta,&nbsp;Zain Merchant,&nbsp;
                  <em>Sayan Ghosh</em>,&nbsp;Willie Neiswanger,&nbsp; and 
                Jesse Thomason

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>arXiv preprint arXiv:2502.09829</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2502.09829.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Evaluating learned robot control policies to determine their physical task-level capabilities costs experimenter time and effort. The growing number of policies and tasks exacerbates this issue. It is impractical to test every policy on every task multiple times; each trial requires a manual environment reset, and each task change involves re-arranging objects or even changing robots. Naively selecting a random subset of tasks and policies to evaluate is a high-cost solution with unreliable, incomplete results. In this work, we formulate robot evaluation as an active testing problem. We propose to model the distribution of robot performance across all tasks and policies as we sequentially execute experiments. Tasks often share similarities that can reveal potential relationships in policy behavior, and we show that natural language is a useful prior in modeling these relationships between tasks. We then leverage this formulation to reduce the experimenter effort by using a cost-aware expected information gain heuristic to efficiently select informative trials. Our framework accommodates both continuous and discrete performance outcomes. We conduct experiments on existing evaluation data from real robots and simulations. By prioritizing informative trials, our framework reduces the cost of calculating evaluation metrics for robot policies across many tasks.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="ghosh-etal-2024-compare" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Compare without Despair: Reliable Preference Evaluation with Generation Separability</div>
          <!-- Author -->
          <div class="author">
          
                  <em>Sayan Ghosh</em>,&nbsp;Tejas Srinivasan,&nbsp; and 
                Swabha Swayamdipta

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em> Nov 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2024.findings-emnlp.747.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Human evaluation of generated language through pairwise preference judgments is pervasive. However, under common scenarios, such as when generations from a model pair are very similar, or when stochastic decoding results in large variations in generations, it results in inconsistent preference ratings. We address these challenges by introducing a meta-evaluation measure, separability, which estimates how suitable a test instance is for pairwise preference evaluation. For a candidate test instance, separability samples multiple generations from a pair of models, and measures how distinguishable the two sets of generations are. Our experiments show that instances with high separability values yield more consistent preference ratings from both human- and auto-raters. Further, the distribution of separability allows insights into which test benchmarks are more valuable for comparing models. Finally, we incorporate separability into ELO ratings, accounting for how suitable each test instance might be for reliably ranking LLMs. Overall, separability has implications for consistent, efficient and robust preference evaluation of LLMs with both human- and auto-raters.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICWSM</abbr></div>

        <!-- Entry bib key -->
        <div id="mendelsohn2023bridging" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Bridging Nations: Quantifying the Role of Multilinguals in Communication on Social Media</div>
          <!-- Author -->
          <div class="author">
          Julia Mendelsohn,&nbsp;
                  <em>Sayan Ghosh</em>,&nbsp;David Jurgens,&nbsp; and 
                Ceren Budak

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the International AAAI Conference on Web and Social Media</em> Nov 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/22174" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Social media enables the rapid spread of many kinds of in- formation, from pop culture memes to social movements. However, little is known about how information crosses linguistic boundaries. We apply causal inference techniques on the European Twitter network to quantify the structural role and communication influence of multilingual users in cross-lingual information exchange. Overall, multilinguals play an essential role; posting in multiple languages increases betweenness centrality by 13%, and having a multilingual network neighbor increases monolingualsâ€™ odds of sharing domains and hashtags from another language 16-fold and 4-fold, respectively. We further show that multilinguals have a greater impact on diffusing information is less accessible to their monolingual compatriots, such as information from far-away countries and content about regional politics, nascent social movements, and job opportunities. By highlighting information exchange across borders, this work sheds light on a crucial component of how information and ideas spread around the world.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="bao-etal-2022-learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning to Mediate Disparities Towards Pragmatic Communication</div>
          <!-- Author -->
          <div class="author">
          Yuwei Bao,&nbsp;
                  <em>Sayan Ghosh</em>,&nbsp; and 
                Joyce Chai

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> May 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2022.acl-long.202.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Human communication is a collaborative process. Speakers, on top of conveying their own intent, adjust the content and language expressions by taking the listeners into account, including their knowledge background, personalities, and physical capabilities. Towards building AI agents with similar abilities in language communication, we propose a novel rational reasoning framework, Pragmatic Rational Speaker (PRS), where the speaker attempts to learn the speaker-listener disparity and adjust the speech accordingly, by adding a light-weighted disparity adjustment layer into working memory on top of speakerâ€™s long-term memory system. By fixing the long-term memory, the PRS only needs to update its working memory to learn and adapt to different types of listeners. To validate our framework, we create a dataset that simulates different types of speaker-listener disparities in the context of referential games. Our empirical results demonstrate that the PRS is able to shift its output towards the language that listeners are able to understand, significantly improve the collaborative task outcome, and learn the disparity more efficiently than joint training.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">W-NUT</abbr></div>

        <!-- Entry bib key -->
        <div id="ghosh-etal-2021-detecting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Detecting Cross-Geographic Biases in Toxicity Modeling on Social Media</div>
          <!-- Author -->
          <div class="author">
          
                  <em>Sayan Ghosh</em>,&nbsp;Dylan Baker,&nbsp;David Jurgens,&nbsp; and 
                Vinodkumar Prabhakaran

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the Seventh Workshop on Noisy User-Generated Text (W-NUT 2021)</em> Nov 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2021.wnut-1.35.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="ndubuisi-obi-etal-2019-wetin" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Wetin dey with these comments? Modeling Sociolinguistic Factors Affecting Code-switching Behavior in Nigerian Online Discussions</div>
          <!-- Author -->
          <div class="author">
          Innocent Ndubuisi-Obi*,&nbsp;Sayan Ghosh*,&nbsp; and 
                David Jurgens

          

          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em> Jul 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/P19-1625.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multilingual individuals code switch between languages as a part of a complex communication process. However, most computational studies have examined only one or a handful of contextual factors predictive of switching. Here, we examine Naija-English code switching in a rich contextual environment to understand the social and topical factors eliciting a switch. We introduce a new corpus of 330K articles and accompanying 389K comments labeled for code switching behavior. In modeling whether a comment will switch, we show that topic-driven variation, tribal affiliation, emotional valence, and audience design all play complementary roles in behavior.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  console.log('Publications script loaded');
  
  // Wait for Jekyll Scholar to render
  setTimeout(function() {
    // Find all bibliography entries
    const bibliographyEntries = document.querySelectorAll('.bibliography li, ol.bibliography li, li');
    console.log('Found bibliography entries:', bibliographyEntries.length);
    
    bibliographyEntries.forEach((entry, index) => {
      console.log('Processing entry', index);
      
      // Look for existing content blocks
      const abstractContent = entry.querySelector('div.abstract');
      const bibtexContent = entry.querySelector('div.bibtex');
      
      // Create our own toggle buttons
      if (abstractContent || bibtexContent) {
        // Create button container
        const buttonContainer = document.createElement('div');
        buttonContainer.className = 'custom-toggle-buttons';
        buttonContainer.style.marginTop = '10px';
        buttonContainer.style.marginBottom = '15px';
        
        // Add abstract button if content exists
        if (abstractContent) {
          const abstractBtn = document.createElement('button');
          abstractBtn.className = 'custom-toggle-btn';
          abstractBtn.textContent = 'Abstract';
          abstractBtn.setAttribute('data-target', `custom-abstract-${index}`);
          buttonContainer.appendChild(abstractBtn);
          
          // Set up abstract content
          abstractContent.id = `custom-abstract-${index}`;
          abstractContent.style.display = 'none';
          abstractContent.classList.add('custom-content');
        }
        
        // Add bibtex button if content exists
        if (bibtexContent) {
          const bibtexBtn = document.createElement('button');
          bibtexBtn.className = 'custom-toggle-btn';
          bibtexBtn.textContent = 'BibTeX';
          bibtexBtn.setAttribute('data-target', `custom-bibtex-${index}`);
          buttonContainer.appendChild(bibtexBtn);
          
          // Set up bibtex content
          bibtexContent.id = `custom-bibtex-${index}`;
          bibtexContent.style.display = 'none';
          bibtexContent.classList.add('custom-content');
        }
        
        // Insert button container after the entry content
        entry.appendChild(buttonContainer);
        
        // Add click handlers
        const buttons = buttonContainer.querySelectorAll('.custom-toggle-btn');
        buttons.forEach(button => {
          button.addEventListener('click', function() {
            const targetId = this.getAttribute('data-target');
            const target = document.getElementById(targetId);
            
            if (target) {
              if (target.style.display === 'none') {
                target.style.display = 'block';
                this.textContent = 'Hide ' + this.textContent;
                this.classList.add('active');
              } else {
                target.style.display = 'none';
                this.textContent = this.textContent.replace('Hide ', '');
                this.classList.remove('active');
              }
            }
          });
        });
      }
    });
  }, 1000);
});
</script>

:ET